{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86d98bd",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "## Telecom Customer Churn Dataset\n",
    "\n",
    "This notebook handles:\n",
    "- Data cleaning and preprocessing\n",
    "- Feature engineering\n",
    "- Creating derived features\n",
    "- Preparing data for modeling\n",
    "\n",
    "**Objectives:**\n",
    "- Handle missing values and data types\n",
    "- Create new informative features\n",
    "- Encode categorical variables\n",
    "- Scale numerical features\n",
    "- Prepare train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e686525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fdfcfc",
   "metadata": {},
   "source": [
    "## 1. Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from data_prep import load_data, clean_data\n",
    "\n",
    "df = load_data('../data/raw/telco_churn.csv')\n",
    "print(f\"\\nOriginal shape: {df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "df_clean = clean_data(df)\n",
    "print(f\"\\nCleaned shape: {df_clean.shape}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nğŸ“Š Data Types After Cleaning:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no missing values\n",
    "print(\"\\nğŸ” Missing Values Check:\")\n",
    "missing = df_clean.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"âœ… No missing values!\")\n",
    "else:\n",
    "    print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577aa541",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature engineering functions\n",
    "from features import create_tenure_groups, create_charge_features, create_service_features\n",
    "\n",
    "# Create tenure groups\n",
    "df_featured = create_tenure_groups(df_clean)\n",
    "\n",
    "print(\"\\nğŸ“Š Tenure Groups:\")\n",
    "print(df_featured['TenureGroup'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1506afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tenure groups\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Tenure group distribution\n",
    "df_featured['TenureGroup'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Distribution of Tenure Groups', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Tenure Group')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Churn rate by tenure group\n",
    "tenure_churn = df_featured.groupby('TenureGroup')['Churn'].apply(lambda x: (x == 'Yes').sum() / len(x) * 100)\n",
    "tenure_churn.plot(kind='bar', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Churn Rate by Tenure Group', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Tenure Group')\n",
    "axes[1].set_ylabel('Churn Rate (%)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca150de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create charge-related features\n",
    "df_featured = create_charge_features(df_featured)\n",
    "\n",
    "print(\"\\nğŸ“Š New Charge Features:\")\n",
    "print(df_featured[['MonthlyCharges', 'TotalCharges', 'AvgMonthlyCharges', 'ChargeRatio']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize charge features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Average Monthly Charges by Churn\n",
    "df_featured.boxplot(column='AvgMonthlyCharges', by='Churn', ax=axes[0], \n",
    "                    patch_artist=True, medianprops=dict(color='red', linewidth=2))\n",
    "axes[0].set_title('Average Monthly Charges by Churn', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Churn')\n",
    "axes[0].set_ylabel('Avg Monthly Charges ($)')\n",
    "plt.sca(axes[0])\n",
    "plt.xticks([1, 2], ['No', 'Yes'])\n",
    "\n",
    "# Charge Ratio by Churn\n",
    "df_featured.boxplot(column='ChargeRatio', by='Churn', ax=axes[1],\n",
    "                    patch_artist=True, medianprops=dict(color='red', linewidth=2))\n",
    "axes[1].set_title('Charge Ratio by Churn', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Churn')\n",
    "axes[1].set_ylabel('Charge Ratio')\n",
    "plt.sca(axes[1])\n",
    "plt.xticks([1, 2], ['No', 'Yes'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cb994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create service bundle features\n",
    "df_featured = create_service_features(df_featured)\n",
    "\n",
    "print(\"\\nğŸ“Š Total Services Distribution:\")\n",
    "print(df_featured['TotalServices'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab43b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize service features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Total Services distribution\n",
    "df_featured['TotalServices'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='lightgreen')\n",
    "axes[0].set_title('Distribution of Total Services', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Services')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Churn rate by Total Services\n",
    "service_churn = df_featured.groupby('TotalServices')['Churn'].apply(lambda x: (x == 'Yes').sum() / len(x) * 100)\n",
    "service_churn.plot(kind='bar', ax=axes[1], color='salmon')\n",
    "axes[1].set_title('Churn Rate by Total Services', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Number of Services')\n",
    "axes[1].set_ylabel('Churn Rate (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b118e1",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "from features import prepare_features_for_modeling\n",
    "\n",
    "X, y, feature_names, numerical_features, categorical_features = prepare_features_for_modeling(df_featured)\n",
    "\n",
    "print(f\"\\nğŸ“Š Features Summary:\")\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "print(f\"Numerical features: {len(numerical_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e58943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature lists\n",
    "print(\"\\nğŸ”¢ Numerical Features:\")\n",
    "for i, feat in enumerate(numerical_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Categorical Features:\")\n",
    "for i, feat in enumerate(categorical_features, 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b24e9",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Data Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Target Distribution in Training Set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nChurn rate in training: {y_train.mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Target Distribution in Test Set:\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "print(f\"Churn rate in test: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2956c79",
   "metadata": {},
   "source": [
    "## 5. Create Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99797968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "from features import get_preprocessor\n",
    "\n",
    "preprocessor = get_preprocessor(numerical_features, categorical_features)\n",
    "\n",
    "print(\"\\nâœ… Preprocessing pipeline created!\")\n",
    "print(\"\\nPipeline steps:\")\n",
    "print(\"1. Numerical features: StandardScaler\")\n",
    "print(\"2. Categorical features: OneHotEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"\\nğŸ“Š Transformed Data Shape:\")\n",
    "print(f\"Training: {X_train_transformed.shape}\")\n",
    "print(f\"Test: {X_test_transformed.shape}\")\n",
    "\n",
    "print(f\"\\nâœ… Features after preprocessing: {X_train_transformed.shape[1]}\")\n",
    "print(\"   (One-hot encoding expanded categorical features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025dabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "try:\n",
    "    # Get numerical feature names\n",
    "    num_features = numerical_features\n",
    "    \n",
    "    # Get categorical feature names after one-hot encoding\n",
    "    cat_encoder = preprocessor.named_transformers_['cat']\n",
    "    cat_features = cat_encoder.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    # Combine all feature names\n",
    "    all_feature_names = list(num_features) + list(cat_features)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Total features after encoding: {len(all_feature_names)}\")\n",
    "    print(\"\\nğŸ”¢ Sample of encoded features:\")\n",
    "    for i, feat in enumerate(all_feature_names[:15], 1):\n",
    "        print(f\"  {i}. {feat}\")\n",
    "    print(f\"  ... and {len(all_feature_names) - 15} more features\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not extract feature names: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9ad89",
   "metadata": {},
   "source": [
    "## 6. Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the engineered dataset\n",
    "output_path = '../data/processed/telco_churn_engineered.csv'\n",
    "df_featured.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Engineered dataset saved to: {output_path}\")\n",
    "\n",
    "# Save train-test splits\n",
    "import joblib\n",
    "\n",
    "splits_data = {\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'numerical_features': numerical_features,\n",
    "    'categorical_features': categorical_features\n",
    "}\n",
    "\n",
    "joblib.dump(splits_data, '../data/processed/train_test_splits.joblib')\n",
    "print(f\"âœ… Train-test splits saved!\")\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(preprocessor, '../data/processed/preprocessor.joblib')\n",
    "print(f\"âœ… Preprocessor saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eb257a",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### âœ… Preprocessing Complete!\n",
    "\n",
    "**What we accomplished:**\n",
    "1. âœ“ Loaded and cleaned the raw data\n",
    "2. âœ“ Created tenure groups for better segmentation\n",
    "3. âœ“ Engineered charge-related features\n",
    "4. âœ“ Created service bundle features\n",
    "5. âœ“ Identified numerical and categorical features\n",
    "6. âœ“ Split data into train and test sets (80/20)\n",
    "7. âœ“ Created preprocessing pipeline with scaling and encoding\n",
    "8. âœ“ Saved all preprocessed data and artifacts\n",
    "\n",
    "**Key Statistics:**\n",
    "- Total samples: {total_samples}\n",
    "- Training samples: {train_samples}\n",
    "- Test samples: {test_samples}\n",
    "- Original features: {original_features}\n",
    "- Engineered features: {engineered_features}\n",
    "- Features after encoding: {encoded_features}\n",
    "\n",
    "**Next Steps:**\n",
    "ğŸ“Œ Proceed to: **03_Modeling_and_Evaluation.ipynb** to train and evaluate ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… PREPROCESSING AND FEATURE ENGINEERING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Š Final Dataset:\")\n",
    "print(f\"  - Total samples: {len(df_featured):,}\")\n",
    "print(f\"  - Features: {len(df_featured.columns)}\")\n",
    "print(f\"  - Churn rate: {(df_featured['Churn'] == 'Yes').mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Train-Test Split:\")\n",
    "print(f\"  - Training: {len(X_train):,} samples\")\n",
    "print(f\"  - Test: {len(X_test):,} samples\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Feature Engineering:\")\n",
    "print(f\"  - Numerical features: {len(numerical_features)}\")\n",
    "print(f\"  - Categorical features: {len(categorical_features)}\")\n",
    "print(f\"  - Total after encoding: {X_train_transformed.shape[1]}\")\n",
    "\n",
    "print(\"\\nâœ… Ready for model training!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
